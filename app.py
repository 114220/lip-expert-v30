import streamlit as st
import cv2
import numpy as np
import time
import os  # æ–°å¢ï¼šç”¨æ–¼æª”æ¡ˆç®¡ç†
from PIL import Image, ImageDraw, ImageFont

# =================================================================
# 1. ç³»çµ±æ ¸å¿ƒé…ç½®
# =================================================================
st.set_page_config(
    page_title="Lip Expert V30 - æ°¸ä¹…å­˜æª”ç‰ˆ",
    page_icon="ğŸ—£ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å®šç¾©å½±ç‰‡å­˜æª”è³‡æ–™å¤¾
VIDEO_SAVE_DIR = "user_videos"
if not os.path.exists(VIDEO_SAVE_DIR):
    os.makedirs(VIDEO_SAVE_DIR)  # å¦‚æœè³‡æ–™å¤¾ä¸å­˜åœ¨ï¼Œå°±å»ºç«‹ä¸€å€‹

@st.cache_resource
def get_mp_tools():
    try:
        import mediapipe as mp
        return {
            "mesh": mp.solutions.face_mesh,
            "draw": mp.solutions.drawing_utils,
            "styles": mp.solutions.drawing_styles
        }
    except Exception as e:
        st.error(f"MediaPipe å•Ÿå‹•å¤±æ•—ï¼š{e}")
        return None

MP_TOOLS = get_mp_tools()

# =================================================================
# 2. èª²ç¨‹è³‡æ–™åº«
# =================================================================
COURSE_DATA = {
    "ğŸŸ¢ å®Œæ•´æ³¨éŸ³ç¬¦è™Ÿ (37éŸ³)": [
        "ã„…", "ã„†", "ã„‡", "ã„ˆ", "ã„‰", "ã„Š", "ã„‹", "ã„Œ",
        "ã„", "ã„", "ã„", 
        "ã„", "ã„‘", "ã„’",
        "ã„“", "ã„”", "ã„•", "ã„–",
        "ã„—", "ã„˜", "ã„™",
        "ã„§", "ã„¨", "ã„©",
        "ã„š", "ã„›", "ã„œ", "ã„", "ã„", "ã„Ÿ", "ã„ ", "ã„¡",
        "ã„¢", "ã„£", "ã„¤", "ã„¥", "ã„¦"
    ],
    "ğŸ‘‹ æ—¥å¸¸å•å€™èˆ‡ç¦®è²Œ": [
        "ä½ å¥½", "æ—©å®‰", "æ™šå®‰", "è¬è¬", "ä¸å®¢æ°£", 
        "å°ä¸èµ·", "æ²’é—œä¿‚", "å†è¦‹", "æ‹œæ‹œ", "è«‹å•"
    ],
    "ğŸ—£ï¸ è¡¨é”éœ€æ±‚": [
        "æˆ‘è¦", "ä¸è¦", "å¥½", "ä¸å¥½", 
        "è‚šå­é¤“", "å£æ¸´", "å–æ°´", "åƒé£¯", 
        "ä¸Šå»æ‰€", "æƒ³ç¡è¦º", "ç—›", "ä¸èˆ’æœ", "å¹«å¿™"
    ],
    "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ å®¶åº­èˆ‡ç¨±è¬‚": [
        "çˆ¸çˆ¸", "åª½åª½", "çˆºçˆº", "å¥¶å¥¶", 
        "å“¥å“¥", "å§Šå§Š", "å¼Ÿå¼Ÿ", "å¦¹å¦¹", 
        "è€å¸«", "é†«ç”Ÿ", "è­·å£«", "æˆ‘è‡ªå·±"
    ],
    "ğŸ”¢ æ•¸å­—èˆ‡æ•¸é‡": [
        "ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", 
        "å…­", "ä¸ƒ", "å…«", "ä¹", "å", 
        "ä¸€ç™¾", "å¤šå°‘éŒ¢", "å¹¾å€‹", "ä¸€é»é»"
    ],
    "ğŸ¥ å£è…”å¾©å¥å‹•ä½œ": [
        "å¤§å¼µå˜´ (å•Š)", "ç”¨åŠ›æŠ¿å˜´ (ä¸€)", "åœ“å”‡å˜Ÿå˜´ (å—š)", 
        "é¼“è…® (åƒé’è›™)", "å·¦å³æ’‡å˜´", "èˆŒé ­å‘ä¸Šèˆ”", "èˆŒé ­å‘ä¸‹ä¼¸"
    ]
}

# =================================================================
# 3. å”‡å½¢åˆ†ææ ¸å¿ƒæ¼”ç®—æ³• (V29: å¯¬å®¹è©•åˆ† + é€²åº¦è¿½è¹¤)
# =================================================================
class LipAnalyzer:
    
    @staticmethod
    def get_drawing_specs():
        import mediapipe as mp
        landmark_spec = mp.solutions.drawing_utils.DrawingSpec(
            color=(255, 255, 255), thickness=1, circle_radius=1
        )
        connection_spec = mp.solutions.drawing_utils.DrawingSpec(
            color=(255, 255, 255), thickness=1
        )
        return landmark_spec, connection_spec

    @staticmethod
    def get_mar(landmarks):
        p13 = np.array([landmarks[13].x, landmarks[13].y])
        p14 = np.array([landmarks[14].x, landmarks[14].y])
        p78 = np.array([landmarks[78].x, landmarks[78].y])
        p308 = np.array([landmarks[308].x, landmarks[308].y])
        v_dist = np.linalg.norm(p13 - p14)
        h_dist = np.linalg.norm(p78 - p308)
        return v_dist / (h_dist + 1e-6)

    @staticmethod
    def get_lip_shape_vector(landmarks):
        indices = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95]
        vector = []
        origin_x = (landmarks[78].x + landmarks[308].x) / 2
        origin_y = (landmarks[78].y + landmarks[308].y) / 2
        scale = np.linalg.norm(np.array([landmarks[78].x, landmarks[78].y]) - 
                               np.array([landmarks[308].x, landmarks[308].y])) + 1e-6

        for idx in indices:
            vector.append((landmarks[idx].x - origin_x) / scale)
            vector.append((landmarks[idx].y - origin_y) / scale)
        return np.array(vector)

    @staticmethod
    def calculate_lenient_score(std_vec, cur_vec, std_mar, cur_mar):
        dist = np.linalg.norm(std_vec - cur_vec)
        shape_score = max(0, 100 - (dist * 120)) 
        mar_diff = abs(std_mar - cur_mar)
        open_score = max(0, 100 - (mar_diff * 150))
        final_score = (shape_score * 0.6) + (open_score * 0.4)
        if final_score < 60 and final_score > 30:
            final_score += 20 
        return min(100, final_score)

    @staticmethod
    def analyze_video_sequence(video_path):
        cap = cv2.VideoCapture(video_path)
        sequence_vectors = []
        sequence_mars = []
        
        with MP_TOOLS["mesh"].FaceMesh(refine_landmarks=True, max_num_faces=1) as face_mesh:
            frame_count = 0
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret: break
                
                frame_count += 1
                if frame_count % 3 != 0: continue 

                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = face_mesh.process(rgb_frame)
                
                if results.multi_face_landmarks:
                    landmarks = results.multi_face_landmarks[0].landmark
                    vec = LipAnalyzer.get_lip_shape_vector(landmarks)
                    mar = LipAnalyzer.get_mar(landmarks)
                    sequence_vectors.append(vec)
                    sequence_mars.append(mar)
        
        cap.release()
        if sequence_vectors:
            return np.array(sequence_mars), np.array(sequence_vectors)
        return None, None

# =================================================================
# 4. ç‹€æ…‹ç®¡ç†
# =================================================================
def init_session_state():
    defaults = {
        'is_practice_mode': False,
        'standard_models': {},
        'uploaded_videos': {},
        'camera_index': 0,
        'current_category': list(COURSE_DATA.keys())[0],
        'current_word': COURSE_DATA[list(COURSE_DATA.keys())[0]][0],
        'smooth_score': 0.0,
        'progress_index': 0,
        'last_match_time': 0
    }
    for key, val in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = val

init_session_state()

# =================================================================
# 5. UI ç¹ªåœ– (å«é€²åº¦æ¢)
# =================================================================
def draw_ui_overlay(frame, text_list, progress=0.0, color=(0, 255, 255)):
    h, w, _ = frame.shape
    img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    try:
        font = ImageFont.truetype("msjh.ttc", 36)
    except:
        font = ImageFont.load_default()
    
    for i, text in enumerate(text_list):
        x, y = 30, 30 + i*50
        draw.text((x-1, y), text, font=font, fill=(0,0,0))
        draw.text((x+1, y), text, font=font, fill=(0,0,0))
        draw.text((x, y-1), text, font=font, fill=(0,0,0))
        draw.text((x, y+1), text, font=font, fill=(0,0,0))
        draw.text((x, y), text, font=font, fill=color)
    
    bar_x, bar_y = 30, 10
    bar_w, bar_h = w - 60, 15
    draw.rectangle([bar_x, bar_y, bar_x + bar_w, bar_y + bar_h], fill=(50, 50, 50))
    fill_w = int(bar_w * progress)
    draw.rectangle([bar_x, bar_y, bar_x + fill_w, bar_y + bar_h], fill=(0, 255, 0))
    
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# =================================================================
# 6. ä¸»ç¨‹å¼ä»‹é¢
# =================================================================

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.title("ğŸ—‚ï¸ èª²ç¨‹é¸å–®")
    selected_category = st.selectbox("é¸æ“‡åˆ†é¡", list(COURSE_DATA.keys()))
    st.session_state.current_category = selected_category
    
    word_list = COURSE_DATA[selected_category]
    selected_word = st.selectbox("é¸æ“‡ç·´ç¿’è©å½™", word_list)
    
    if selected_word != st.session_state.current_word:
        st.session_state.current_word = selected_word
        st.session_state.is_practice_mode = False
        st.session_state.progress_index = 0

    st.divider()
    st.write("âš™ï¸ è¨­å®š")
    st.session_state.camera_index = st.number_input("æ”å½±æ©Ÿ ID", 0, 5, 0)
    
    if st.button("ğŸ”„ é‡ç½®é€²åº¦ (å¾é ­é–‹å§‹)"):
        st.session_state.progress_index = 0
        st.session_state.smooth_score = 0.0

st.title(f"ğŸ—£ï¸ ç•¶å‰ç·´ç¿’ï¼š{st.session_state.current_word}")
st.caption("V30 æ°¸ä¹…å­˜æª”ç‰ˆï¼šå½±ç‰‡æœƒè‡ªå‹•å„²å­˜åœ¨ user_videos è³‡æ–™å¤¾")

tab1, tab2 = st.tabs(["ğŸ“º 1. æ•™å­¸èˆ‡å»ºæ¨¡", "ğŸ¯ 2. å¯¦æˆ°ç·´ç¿’è©•åˆ†"])

# =================================================
# TAB 1: æ•™å­¸å½±ç‰‡å€ (æ ¸å¿ƒä¿®æ”¹è™•ï¼šæ°¸ä¹…å­˜æª”é‚è¼¯)
# =================================================
with tab1:
    col1, col2 = st.columns([1, 1])
    
    # å®šç¾©è©²è©å½™çš„æ°¸ä¹…æª”æ¡ˆè·¯å¾‘
    # Windows ç³»çµ±ä¸æ”¯æ´æª”åæœ‰ç‰¹æ®Šç¬¦è™Ÿï¼Œé€™è£¡å‡è¨­è©å½™éƒ½æ˜¯ä¸­æ–‡æˆ–è‹±æ–‡
    current_video_filename = f"{st.session_state.current_word}.mp4"
    current_video_path = os.path.join(VIDEO_SAVE_DIR, current_video_filename)

    with col1:
        st.subheader("æ­¥é©Ÿ 1ï¼šå½±ç‰‡ç®¡ç†")
        
        # 1. æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰å­˜æª”
        file_exists = os.path.exists(current_video_path)
        
        if file_exists:
            st.success(f"ğŸ“‚ å·²æ‰¾åˆ°ã€Œ{st.session_state.current_word}ã€çš„æ­·å²å½±ç‰‡ï¼")
            # å¦‚æœé‚„æ²’è¼‰å…¥åˆ° sessionï¼Œå°±è¼‰å…¥
            if st.session_state.current_word not in st.session_state.uploaded_videos:
                st.session_state.uploaded_videos[st.session_state.current_word] = current_video_path
        else:
            st.info("å°šæœªä¸Šå‚³æ­¤è©å½™çš„å½±ç‰‡ã€‚")

        # 2. ä¸Šå‚³ä»‹é¢ (ç„¡è«–æœ‰ç„¡èˆŠæª”ï¼Œéƒ½å¯ä»¥ä¸Šå‚³è¦†è“‹)
        video_key = f"uploader_{st.session_state.current_word}"
        video_file = st.file_uploader("ä¸Šå‚³æ–°å½±ç‰‡ (å°‡è¦†è“‹èˆŠæª”)", type=['mp4', 'mov'], key=video_key)
        
        if video_file:
            # === æ°¸ä¹…å­˜æª”é‚è¼¯ ===
            with open(current_video_path, "wb") as f:
                f.write(video_file.getbuffer())
            
            # æ›´æ–° session
            st.session_state.uploaded_videos[st.session_state.current_word] = current_video_path
            st.toast(f"âœ… å½±ç‰‡å·²æ°¸ä¹…å„²å­˜è‡³ {current_video_path}")
            
            # ç‚ºäº†è®“ä»‹é¢åˆ·æ–°é¡¯ç¤ºæ–°å½±ç‰‡ï¼Œå¯ä»¥è€ƒæ…® rerunï¼Œä½†é€™è£¡å…ˆæ‰‹å‹•æ›´æ–°è®Šæ•¸
            file_exists = True 

        # 3. é¡¯ç¤ºå½±ç‰‡
        if file_exists:
            st.video(current_video_path)
        
    with col2:
        st.subheader("æ­¥é©Ÿ 2ï¼šAI åºåˆ—å»ºæ¨¡")
        
        # é€™è£¡çš„é‚è¼¯ä¹Ÿæ”¹ç‚ºè®€å–æ°¸ä¹…è·¯å¾‘
        target_video_path = st.session_state.uploaded_videos.get(st.session_state.current_word)
        
        # å¦‚æœ session æ²’æŠ“åˆ°ï¼Œä½†ç¡¬ç¢Ÿæœ‰æª”æ¡ˆï¼Œå°±ç”¨ç¡¬ç¢Ÿçš„
        if not target_video_path and os.path.exists(current_video_path):
            target_video_path = current_video_path

        if target_video_path:
            if st.button("ğŸš€ å»ºç«‹è¿½è¹¤æ¨¡å‹", width='stretch', type="primary"):
                with st.spinner("åˆ†æä¸­..."):
                    seq_mars, seq_vectors = LipAnalyzer.analyze_video_sequence(target_video_path)
                    
                    if seq_vectors is not None:
                        st.session_state.standard_models[st.session_state.current_word] = {
                            "mars": seq_mars,
                            "vectors": seq_vectors,
                            "length": len(seq_vectors)
                        }
                        st.success(f"âœ… æ¨¡å‹å·²å»ºç«‹ï¼åŒ…å« {len(seq_vectors)} å€‹é€£çºŒå‹•ä½œé»ã€‚")
                    else:
                        st.error("åˆ†æå¤±æ•—ï¼Œè«‹æª¢æŸ¥å½±ç‰‡ã€‚")
        else:
            st.warning("ğŸ‘ˆ è«‹å…ˆä¸Šå‚³å½±ç‰‡")

# =================================================
# TAB 2: ç·´ç¿’è©•åˆ†å€
# =================================================
with tab2:
    col_p1, col_p2 = st.columns([3, 1])
    
    with col_p2:
        st.subheader("æ§åˆ¶é¢æ¿")
        if st.button("ğŸŸ¢ é–‹å§‹ç·´ç¿’", width='stretch'):
            if st.session_state.current_word in st.session_state.standard_models:
                st.session_state.is_practice_mode = True
                st.session_state.progress_index = 0 
                st.session_state.smooth_score = 0.0
            else:
                st.error("è«‹å…ˆå»ºç«‹æ¨¡å‹ï¼")
                
        if st.button("ğŸ”´ åœæ­¢ç·´ç¿’", width='stretch'):
            st.session_state.is_practice_mode = False

        st.divider()
        st.write("### å³æ™‚è©•åˆ†")
        score_gauge = st.empty()
        status_box = st.empty()
        
    with col_p1:
        st.write("### é¡é ­ç•«é¢ (å«é€²åº¦æ¢)")
        cam_placeholder = st.empty()
        lm_spec, conn_spec = LipAnalyzer.get_drawing_specs()
        
        if st.session_state.is_practice_mode:
            cap = cv2.VideoCapture(st.session_state.camera_index)
            
            model_data = st.session_state.standard_models[st.session_state.current_word]
            std_vectors = model_data["vectors"]
            std_mars = model_data["mars"]
            total_frames = model_data["length"]
            
            with MP_TOOLS["mesh"].FaceMesh(refine_landmarks=True, max_num_faces=1) as face_mesh:
                while st.session_state.is_practice_mode and cap.isOpened():
                    ret, frame = cap.read()
                    if not ret: break
                    
                    frame = cv2.flip(frame, 1)
                    h, w, _ = frame.shape
                    
                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    results = face_mesh.process(rgb_frame)
                    
                    overlay = frame.copy()
                    display_text = ["ç­‰å¾…å‹•ä½œ..."]
                    current_progress = st.session_state.progress_index / total_frames
                    
                    if results.multi_face_landmarks:
                        MP_TOOLS["draw"].draw_landmarks(
                            image=overlay,
                            landmark_list=results.multi_face_landmarks[0],
                            connections=MP_TOOLS["mesh"].FACEMESH_LIPS,
                            landmark_drawing_spec=lm_spec,
                            connection_drawing_spec=conn_spec
                        )
                        cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame)

                        landmarks = results.multi_face_landmarks[0].landmark
                        cur_mar = LipAnalyzer.get_mar(landmarks)
                        cur_vec = LipAnalyzer.get_lip_shape_vector(landmarks)
                        
                        current_idx = st.session_state.progress_index
                        search_window_size = 15 
                        
                        start_search = current_idx
                        end_search = min(current_idx + search_window_size, total_frames)
                        
                        if start_search < end_search:
                            window_vectors = std_vectors[start_search:end_search]
                            dists = np.linalg.norm(window_vectors - cur_vec, axis=1)
                            local_best_idx = np.argmin(dists) 
                            global_best_idx = start_search + local_best_idx 
                            
                            target_vec = std_vectors[global_best_idx]
                            target_mar = std_mars[global_best_idx]
                            
                            score = LipAnalyzer.calculate_lenient_score(target_vec, cur_vec, target_mar, cur_mar)
                            
                            if score > 60:
                                st.session_state.progress_index = global_best_idx
                            
                            st.session_state.smooth_score = (st.session_state.smooth_score * 0.8) + (score * 0.2)
                            final_score = int(st.session_state.smooth_score)
                            
                            score_gauge.metric("å¾—åˆ†", f"{final_score} åˆ†")
                            
                            if final_score > 80:
                                status_box.success("âœ¨ å®Œç¾ï¼è·Ÿä¸Šäº†ï¼")
                                cv2.putText(frame, "GOOD!", (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
                            elif final_score > 60:
                                status_box.info("ğŸ‘Œ ç¹¼çºŒä¿æŒ")
                            else:
                                status_box.warning("â³ åŠ æ²¹...")

                            display_text = [
                                f"è©å½™ï¼š{st.session_state.current_word}",
                                f"é€²åº¦ï¼š{int((st.session_state.progress_index / total_frames)*100)}%",
                                f"åˆ†æ•¸ï¼š{final_score}"
                            ]
                            
                            if st.session_state.progress_index >= total_frames - 2:
                                cv2.putText(frame, "FINISH!", (w//2-100, h//2), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 4)
                        else:
                            display_text = ["ç·´ç¿’å®Œæˆï¼", "è«‹æŒ‰é‡ç½®"]
                            status_box.success("ğŸ‰ ç·´ç¿’çµæŸï¼")

                    else:
                        display_text = ["æœªåµæ¸¬åˆ°è‡‰éƒ¨"]

                    frame = draw_ui_overlay(frame, display_text, progress=current_progress)
                    cam_placeholder.image(frame, channels="BGR", width='stretch')
                    time.sleep(0.01)
            
            cap.release()
            cam_placeholder.empty()

st.markdown("---")
st.markdown("""
<div style="text-align: center; color: gray;">
    Lip Expert V30 | æ°¸ä¹…å­˜æª”ç‰ˆ | å½±ç‰‡æœƒå„²å­˜æ–¼ user_videos è³‡æ–™å¤¾
</div>
""", unsafe_allow_html=True)